---
title: "Introduction to Causal Inference"
subtitle: "Data Exercise"
format:
  revealjs: 
    slide-number: true
    smaller: false
    scrollable: true
    incremental: true
    echo: true
    chalkboard: true 
    buttons: false
    preview-links: auto
    theme: moon
    embed-resources: false
    code-fold: true
    code-overflow: scroll
    code-line-numbers: true
    auto-stretch: true
    html-math-method: katex
    progress: true
    bibliography: references.bib
execute:
  warning: false
---


## load Data 

```{r}
#|label: source
source("https://raw.githubusercontent.com/go-bayes/templates/main/functions/funs.R")
```


## Load Data

```{r}
#|label: load-data
#|eval: false
######### PART 1: DATA EXCERCISE ##############

# Create a folder called "data", in your Rstudio project. Download this file, add it to your the folder called "data" in your Rstudio project.
# "https://www.dropbox.com/s/vwqijg4ha17hbs1/nzavs_dat_synth_t10_t12?dl=0"



# This will read the synthetic data into Rstudio.  Note that the arrow package allows us to have lower memory demands in the storage and retrieval of data.
nzavs_synth <-
  arrow::read_parquet(here::here("data", "nzavs_dat_synth_t10_t12"))

```

## Inspect

```{r}
#| eval: false
## inspect colnames
colnames(nzavs_synth)

## inspect data properties
str(nzavs_synth)

```

## Prepare data


```{r}
baseline_vars = c(
  "edu",
  "male",
  "eth_cat",
  "employed",
  "gen_cohort",
  "nz_dep2018",
  "nzsei13",
  "partner",
  "parent",
  "pol_orient",
  "rural_gch2018",
  "agreeableness",
  "conscientiousness",
  "extraversion",
  "honesty_humility",
  "openness",
  "neuroticism",
  "modesty",
  "religion_identification_level"
)


## Step 2, select the exposure variable.  This is the "cause"

exposure_var = c("perfectionism")


## step 3. select the outcome variable.  These are the outcomes.
outcome_vars_reflective = c("meaning_purpose",
                            "meaning_sense")


# optional: select exclusion variables (this will not be necessary most of the time)
exclude_vars = c("year_measured")


# the function "create_wide_data" should be in your environment. If not, make sure to run the first line of code in this script once more.  You may ignore the warnings.

prep_reflective <-
  create_wide_data(
    dat_long = nzavs_synth,
    #nzavs_synth,
    baseline_vars = baseline_vars,
    exposure_var = exposure_var,
    outcome_vars = outcome_vars_reflective
  )



# check. Note that any column that is the exposure or an outcome is added to "t0_".  This ensures the strongest possible confounding control, as described by VanderWeele:
# https://cdn1.sph.harvard.edu/wp-content/uploads/sites/603/2020/09/OutcomeWide_StatisticalScience.pdf

colnames(prep_reflective)
# if the data is not working, you much run the code below to make the object in an object of the class dataframe.
# prep_reflective <- as.data.frame(prep_reflective)
```


## create composite scores for constructs 

```{r}

library(tidyverse) # should be loaded
 dt_ref <- prep_reflective |>
  mutate(id = factor(1:nrow(prep_reflective))) |>
  mutate(t1_perfectionism = round(t1_perfectionism)) |> # we create a three-level exposure to enable clear causal contrasts. We could also use a continous variable.
  mutate(
    t1_perfectionism_coarsen = cut(
      t1_perfectionism,
      breaks = c(1, 4, 5, 7),
      include.lowest = TRUE,
      include.highest = TRUE,
      na.rm = TRUE,
      right = FALSE
    )
  ) |>
  mutate(
    t0_eth_cat = as.factor(t0_eth_cat),
    t0_rural_gch2018 = as.factor(t0_rural_gch2018),
    t0_gen_cohort = as.factor(t0_gen_cohort)
  ) |>
  group_by(id) |>
  dplyr::mutate(t2_meaning = mean(c(t2_meaning_purpose,
                                    t2_meaning_sense),
                                  na.rm = TRUE)) |>
  ungroup() |>
  # transform numeric variables into z scores (improves estimation)
  dplyr::mutate(across(where(is.numeric), ~ scale(.x), .names = "{col}_z")) %>%
  # select only factors and numeric values that are z-scores
  select(id,
         where(is.factor),
         t1_perfectionism, # for comparison
         ends_with("_z"), ) |>
  # tidy data frame so that the columns are ordered by time (useful for more complex models)
  relocate(id, .before = starts_with("t1_"))   |>
  relocate(starts_with("t0_"), .before = starts_with("t1_"))  |>
  relocate(starts_with("t2_"), .after = starts_with("t1_"))


# inspect
levels(dt_ref$t1_perfectionism_coarsen)


# rename levels
dt_ref$t1_perfectionism_coarsen <-
  factor(
    dt_ref$t1_perfectionism_coarsen,
    levels = c("[1,4)", "[4,5)", "[5,7]"),
    labels = c("low", "medium", "high"),
    ordered = TRUE
  )
```


## save your dataframe for future use

```{r}
#|eval: false
# make dataframe
dt_ref = as.data.frame(dt_ref)

# save data
saveRDS(dt_ref, here::here("data", "dt_ref"))

# read -- you may start here if you need to repeat the analysis

dt_ref <- readRDS(here::here("data", "dt_ref"))
```


## prepare models


```{r}

dt_ref <- readRDS(here::here("data", "dt_ref"))

# needs to be data frame
dt_ref = data.frame(dt_ref)

# simplicity
df = dt_ref 

# this is the continuous exposure
X = "t1_perfectionism_z"

# this is a categorical exposure
X_pc <- "t1_perfectionism_coarsen"


# set our outcome variable:
Y = "t2_meaning_z" #note that we have created all numeric values into z-scores.  This will facilitate estimation and also interpretation. The outcome is expressed in standard deviation units


# Get baseline names
baseline_vars_reflective_cont = dt_ref |>
  dplyr::select(starts_with("t0")) |> colnames()

# See what we have created:  These are all the "t0_" variables.
# baseline_vars_reflective_cont


# to run these models our data need to be a dataframe (not a tibble or another kind of obect)
# above we've made the data a dataframe, but lets repeat in case you skipped that steip

dt_ref = as.data.frame(dt_ref)


# create our formula string, this time for the categorical variable.
formula_str_X <-
  paste(Y,
        "~",
        X ,
        "*",
        "(",
        paste(baseline_vars_reflective_cont, collapse = "+"),
        ")")
formula_str_X

## regression based control


# fit model
m1 <- glm(as.formula(formula_str_X),
          # shortcut
          #  weights = weights, # will use weights with propensity score models
          family = "gaussian",
          data = df)

# we can look at the coefficients of this model, but again, it would be a mistake to interpret them
summary(m1)
```




# simulate coefficients for the continuous exposure

```{r}
library(clarify)
nsims = 200
sim_model_r <- sim(m1, n = nsims)


# set to number of cores on your machine, e.g.
cores = 2

# simulate effect as modified
sim_estimand_r <- sim_ame(sim_model_r,
                          var = X,
                          cl = cores,
                          verbose = FALSE)


# this is the difference in expectations between everyone in the population being subject to a one standard deviation increase in perfectionism
# and everyone being subject to an average level of perfectionism.


# Estimate  2.5 % 97.5 %
#   dY/d(t1_perfectionism_z)   -0.160 -0.178 -0.140

summary(sim_estimand_r)


```

## Coarsened variable.


```{r}
# create our formula string:
formula_str_X_pc <-
  paste(Y,
        "~",
        X_pc ,
        "*",
        "(",
        paste(baseline_vars_reflective_cont, collapse = "+"),
        ")")

formula_str_X_pc



# fit model
m2 <- glm(as.formula(formula_str_X_pc),
          # shortcut
          #  weights = weights, # will use weights with propensity score models
          family = "gaussian",
          data = df)

# we can look at the coefficients of this model, but again it would be a mistake to interpret them

summary(m2)

```

##  simulate coefficients

```{r}
library(clarify)
nsims = 200
sim_model_r2 <- sim(m2, n = nsims)


# set to number of cores on your machine, e.g.
cores = 4

# simulate effect as modified
sim_estimand_r2 <- sim_ame(sim_model_r2,
                           var = X_pc,
                           cl = cores,
                           verbose = FALSE)




summary(sim_estimand_r2)

```

##  Suppose we want to contrast everyone being assigned to medium with everyone being assigned to high.


```{r}
sim_estimand_r2_focal <-
  transform(sim_estimand_r2, RD = `E[Y(low)]` - `E[Y(high)]`)


# RD describes the causal contrast on the risk difference scale.
summary(sim_estimand_r2_focal)


# The ATE for the effect of moving from low to high is .26 a standard deviation unit in meaning.  What this means is that the expected loss of meaning from perfectionism is about a quarter standard deviation


# > summary(sim_estimand_r2)
# Estimate   2.5 %  97.5 %
# E[Y(low)]      0.0747  0.0519  0.0950
# E[Y(medium)]  -0.1220 -0.1534 -0.0788
# E[Y(high)]    -0.1872 -0.2408 -0.1360


# We interpret these contrasts as the expected effects were everyone "low" verses everyone assigned "medium" versus everyone assigned "high"

```



## CAUSAL GRAPHS

```{r}
# also load the ggdag package
if(!require(ggdag)){
  # Install the package if it is not already installed
  install.packages("ggdag")
}
# load the ggdag package
library(ggdag)
```





## Problem 1: bilingualism on cognitive abilities

```{r}

## Using the DAG below as a starting point, create a DAG in R using the `ggdag` package that represents the causal relationships among bilingualism (B), cognitive abilities (C), and socioeconomic status (S).



dag1 <- dagify(C ~ B + S,
               B ~ S,
               coords = list(x = c(S = 1, B = 2, C = 3),
                             y = c(S = 1, B = 2, C = 1)),
               exposure = "B",
               outcome = "C")

# inspect
tidy_dagitty(dag1)

dag1_t <- tidy_dagitty(dag1)

# # plot
# ggdag(dag1_t)
# 
# # view
# ggdag::ggdag_paths(dag1_t)
# 
# # inspect
# ggdag_parents(dag1_t, "B")

# find adjustment set: adjusting for S is sufficient to control for confounding (on the model's assumptions)
ggdag_adjustment_set(dag1_t)
```
