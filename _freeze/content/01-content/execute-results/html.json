{
  "hash": "62363a8881fbddffdb8a57321b2eee88",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Asking questions in cross-cultural psychology\"\ndate: \"2023-FEB-28\"\nbibliography: /Users/joseph/GIT/templates/bib/references.bib\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell caption='dag'}\n::: {.cell-output-display}\n![A caual graph ](01-content_files/figure-html/fig-line-plot-1.png){#fig-line-plot width=60%}\n:::\n:::\n\n\n\n## Lecture: Introduction to the Course\n\n\n\n## Slides\n\n[PREVIEW](/slides/01-slides.html)\n\n<div>\n\n\n```{=html}\n<iframe class=\"slide-deck\" src=\"/slides/01-slides.html\"></iframe>\n```\n\n\n</div>\n\nOpen in browser [here](/slides/01-slides.html){target=\"_blank\"}\n\n## Background Readings\n\n[@he2012]\n\n[@vandevijver2021]\n\n[@berry1989]\n\n\n## Lab: Introduction to R. \n\n\n# Session 1: Installing R and RStudio\n\n## Introduction\n\nThis session is designed to introduce you to R and RStudio, the essential tools for statistical analysis in cross-cultural psychology. We aim to familiarise you with the software and enable you to simulate and manipulate data from the beginning.\n\n## Installing R\n\n1. Visit the Comprehensive R Archive Network (CRAN) at [https://cran.r-project.org/](https://cran.r-project.org/).\n2. Select the version of R suitable for your operating system (Windows, Mac, or Linux).\n3. Download and install it by following the on-screen instructions.\n\n## Installing RStudio\n\n1. Go to the RStudio download page at [https://www.rstudio.com/products/rstudio/download/](https://www.rstudio.com/products/rstudio/download/).\n2. Choose the free version of RStudio Desktop, and download it for your operating system.\n3. Install RStudio by following the provided instructions.\n\n## Familiarizing Yourself with RStudio\n\n- **Console**: Executes R code line by line.\n- **Source Editor**: Allows you to write and execute scripts (series of commands).\n- **Environment**: Displays variables and data you've loaded.\n- **Files/Plots/Packages/Help**: Allows you to navigate your files, view plots, manage packages, and access R documentation.\n\n## Basic R Commands\n\nLet us start by using R as a calculator. This will help you understand how to execute simple commands in the console.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Addition\n3 + 2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5\n```\n\n\n:::\n\n```{.r .cell-code}\n# Subtraction\n5 - 2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3\n```\n\n\n:::\n\n```{.r .cell-code}\n# Multiplication\n3 * 2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6\n```\n\n\n:::\n\n```{.r .cell-code}\n# Division\n10 / 2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5\n```\n\n\n:::\n\n```{.r .cell-code}\n# Modulus\n7 %% 2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n\n```{.r .cell-code}\n# Exponentiation\n2 ^ 3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 8\n```\n\n\n:::\n\n```{.r .cell-code}\n# Integer Division\n10 %/% 3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3\n```\n\n\n:::\n:::\n\n\n### Exercise 1: Installing the `tidyverse` Package\n\nIn this exercise, you will install the `tidyverse` package, a collection of R packages designed for data science. Follow the steps below to complete the installation:\n\n1. **Open RStudio:** Start by launching RStudio on your computer.\n\n2. **Access Help Tab:** Locate and click on the \"Help\" tab in the lower right pane of RStudio.\n\n3. **Search for Installation Instructions:** In the search bar within the \"Help\" tab, type in \"install packages\" and press Enter. Browse through the help documents if available. (Note: The specific steps to search within the Help tab might vary based on RStudio version and setup. If you cannot find the option to search for \"install packages\" directly in the Help tab, proceed to the next step.)\n\n4. **Open Package Installation:**\n    - Alternatively, you can directly access the package installation option by going to the \"Tools\" menu at the top of RStudio.\n    - Select \"Install Packages...\" from the dropdown menu.\n\n5. **Install `tidyverse`:**\n    - In the \"Install Packages\" dialogue box, you'll find a field to type in the name of the package you wish to install. Type `tidyverse` into this field.\n    - Ensure the \"Install dependencies\" checkbox is ticked. This option ensures that any additional packages needed by `tidyverse` are also installed.\n\n6. **Begin Installation:**\n    - Click on the \"Install\" button to start the installation process.\n\n7. **Wait for Completion:** The installation might take a few minutes. Monitor the progress in the \"Console\" pane. Once the installation is complete, you will see a message in the console indicating that the process has finished.\n\n8. **Loading `tidyverse`:** After successful installation, you can load the `tidyverse` package into your R session by typing `library(tidyverse)` in the console and pressing Enter.\n\n\n\n## Simulating Data in R\n\nSimulating data is a powerful method to understand statistical concepts and data manipulation. Let's simulate a simple dataset representing scores from two cultural groups.\n\n\n#### Step 1: Setting Up Your R Environment\n\nBefore simulating data, ensure R or RStudio is installed and open. RStudio provides a user-friendly interface for R, which can simplify the process of writing and executing R scripts.\n\n#### Step 2: Setting a Seed for Reproducibility\n\nTo ensure that your simulated data can be reproduced exactly, it's good practice to set a seed before generating random data. This makes your analyses and simulations replicable.\n\n```r\nset.seed(123) # use any number to set the seed\n```\n\n#### Step 3: Simulating Continuous Data\n\nTo simulate continuous data, you can use functions like `rnorm()` for normal distributions, `runif()` for uniform distributions, etc. Here’s how to simulate 100 normally distributed data points with a mean of 50 and a standard deviation of 10:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 100 # number of observations\nmean <- 50\nsd <- 10\ndata_continuous <- rnorm(n, mean, sd)\n```\n:::\n\n\n#### Step 4: Simulating Categorical Data\n\nCategorical data can be simulated using the `sample()` function. For example, to simulate a binary variable (e.g., gender) with two levels for 100 observations:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels <- c(\"Male\", \"Female\")\ndata_categorical <- sample(levels, n, replace = TRUE)\n```\n:::\n\n\n#### Step 5: Simulating Data Frames\n\nData frames are used in R to store data tables. To simulate a dataset with both continuous and categorical data, you can combine the above steps:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a data frame with simulated data for ID, Gender, Age, and Income\ndata_frame <- data.frame(\n  # generate a sequence of IDs from 1 to n\n  ID = 1:n,\n  \n  # randomly assign 'Male' or 'Female' to each observation\n  Gender = sample(c(\"Male\", \"Female\"), n, replace = TRUE),\n  \n  # simulate 'Age' data: normally distributed with mean 30 and sd 5\n  Age = rnorm(n, mean = 30, sd = 5),\n  \n  # simulate 'Income' data: normally distributed with mean 50000 and sd 10000\n  Income = rnorm(n, mean = 50000, sd = 10000)\n)\n```\n:::\n\n\n\nNote that you can sample probabilistically for your groups\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 100 # total number of observations\n\n# sample 'Gender' with a 40/60 proportion for Male/Female\nGender = sample(c(\"Male\", \"Female\"), n, replace = TRUE, prob = c(0.4, 0.6))\n```\n:::\n\n\n\n#### Step 6: Add Complexity\n\nTo simulate more complex datasets, you can introduce relationships between variables. For instance, simulating age and income with a correlation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set the number of observations\nn <- 100\n\n# simulate the 'Age' variable\nmean_age <- 30\nsd_age <- 5\nAge <- rnorm(n, mean = mean_age, sd = sd_age)\n\n# define coefficients explicitly\nintercept <- 20000   # Intercept for the income equation\nbeta_age <- 1500     # Coefficient for the effect of age on income\nerror_sd <- 10000    # Standard deviation of the error term\n\n# simulate 'Income' based on 'Age' and defined coefficients\nIncome <- intercept + beta_age * Age + rnorm(n, mean = 0, sd = error_sd)\n\n# create a data frame to hold the simulated data\ndata_complex <- data.frame(Age, Income)\n```\n:::\n\n\n#### Step 7: Visualising Simulated Data\n\nVisualising your simulated data can help understand its distribution and relationships. Use the `ggplot2` package for this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nggplot(data_complex, aes(x = Age, y = Income)) +\n  geom_point() +\n  theme_minimal() +\n  labs(title = \"Simulated Age vs. Income\", x = \"Age\", y = \"Income\")\n```\n\n::: {.cell-output-display}\n![](01-content_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n## Practice\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123) #  reproducibility\ngroupA_scores <- rnorm(100, mean = 100, sd = 15) # simulate scores for group A\ngroupB_scores <- rnorm(100, mean = 105, sd = 15) # simulate scores for group B\n\n# ombine into a data frame\nscores_df <- data.frame(Group = rep(c(\"A\", \"B\"), each = 100), Scores = c(groupA_scores, groupB_scores))\n\n# commands to view data\nstr(scores_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t200 obs. of  2 variables:\n $ Group : chr  \"A\" \"A\" \"A\" \"A\" ...\n $ Scores: num  91.6 96.5 123.4 101.1 101.9 ...\n```\n\n\n:::\n\n```{.r .cell-code}\n# summary of columns\nsummary(scores_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Group               Scores      \n Length:200         Min.   : 65.36  \n Class :character   1st Qu.: 92.59  \n Mode  :character   Median :101.38  \n                    Mean   :102.37  \n                    3rd Qu.:111.59  \n                    Max.   :153.62  \n```\n\n\n:::\n\n```{.r .cell-code}\n# top rows\nhead(scores_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Group    Scores\n1     A  91.59287\n2     A  96.54734\n3     A 123.38062\n4     A 101.05763\n5     A 101.93932\n6     A 125.72597\n```\n\n\n:::\n\n```{.r .cell-code}\n# bottom rows\ntail(scores_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Group    Scores\n195     B  85.33798\n196     B 134.95820\n197     B 114.01063\n198     B  86.23093\n199     B  95.83251\n200     B  87.21780\n```\n\n\n:::\n:::\n\n\n\n## Visualising simulated data\n\nUnderstanding your data visually is as important as the statistical analysis itself. Let's create a simple plot to compare the score distributions between the two groups.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(ggplot2)) {\n  install.packages(\"ggplot2\")\n  library(ggplot2)\n} else {\n  library(ggplot2)\n}\n\n# plot your data\nggplot(scores_df, aes(x = Group, y = Scores, fill = Group)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(title = \"Score Distribution by Group\", x = \"Group\", y = \"Scores\")\n```\n\n::: {.cell-output-display}\n![Score Distribution by Group](01-content_files/figure-html/visualize-data-1.png){width=672}\n:::\n:::\n\n\n\n## Histogram {#sec-histogram}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\n# H=histograms for both groups\nggplot(scores_df, aes(x = Scores, fill = Group)) +\n  geom_histogram(binwidth = 5, color = \"black\") +\n  labs(title = \"Distribution of Scores\",\n       x = \"Scores\",\n       y = \"Frequency\") +\n  facet_wrap(~Group, ncol = 1)\n```\n\n::: {.cell-output-display}\n![](01-content_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n## Excercise 1\n\n1. Modify the simulation parameters to change each group's mean and standard deviation. Observe how these changes affect the distribution.\n\n2. Go to the [histogram](#sec-histogram). Experiment with different bin widths. In your own words, how do large and small numbers speak differently to the data? When might you use one histogram and not another. \n\n\n## Simulating data for familiar statistical tests \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulate some data\ndata <- rnorm(100, mean = 5, sd = 1) # 100 random normal values with mean = 5\n\n# perform one-sample t-test\n# testing if the mean of the data is reliably different from 4\nt.test(data, mu = 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  data\nt = 11.796, df = 99, p-value < 2.2e-16\nalternative hypothesis: true mean is not equal to 4\n95 percent confidence interval:\n 4.931989 5.308942\nsample estimates:\nmean of x \n 5.120465 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulate data for two groups\ngroup1 <- rnorm(50, mean = 5, sd = 1) # 50 random normal values, mean = 5\ngroup2 <- rnorm(50, mean = 5.5, sd = 1) # 50 random normal values, mean = 5.5\n\n# two-sample t-test\nt.test(group1, group2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  group1 and group2\nt = -2.0293, df = 97.95, p-value = 0.04514\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.837548023 -0.009343886\nsample estimates:\nmean of x mean of y \n 5.002054  5.425500 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulate pre-test and post-test scores\npre_test <- rnorm(30, mean = 80, sd = 10)\npost_test <- rnorm(30, mean =  pre_test + 5, sd = 5) # assume an increase\n\n# perform paired t-test\nt.test(pre_test, post_test, paired = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPaired t-test\n\ndata:  pre_test and post_test\nt = -4.7761, df = 29, p-value = 4.725e-05\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -6.785042 -2.716352\nsample estimates:\nmean difference \n      -4.750697 \n```\n\n\n:::\n:::\n\n\n\n## Equivalence of ANOVA and Regression\n\n\nWe will simulate data in R to show that a one-way ANOVA is a special case of linear regression with categorical predictors. We will give some reasons for preferring regression (in some settings).\n\n## Method\n\nFirst, we simulate a dataset with one categorical independent variable with three levels (groups) and a continuous outcome (also called a \"dependant\") variable. This setup allows us to apply both ANOVA and linear regression for comparison.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# nice tables\nif (!require(parameters)) {\n  install.packages(\"parameters\")\n  library(parameters)\n} else {\n  library(parameters)\n}\n\n\nset.seed(321) # reproducibility\nn <- 90 # total number of observations\nk <- 3 # number of groups\n\n# simulate independent variable (grouping factor)\ngroup <- factor(rep(1:k, each = n/k))\n\n# inspect\nstr(group)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Factor w/ 3 levels \"1\",\"2\",\"3\": 1 1 1 1 1 1 1 1 1 1 ...\n```\n\n\n:::\n\n```{.r .cell-code}\n# simulate outcome variable\nmeans <- c(100, 100, 220) # Mean for each group\nsd <- 15 # Standard deviation (same for all groups)\n\n# generate random data\ny <- rnorm(n, mean = rep(means, each = n/k), sd = sd)\n\n\n# make data frame\ndf_1 <- cbind.data.frame(y, group)\n\nanova_model <- aov(y ~ group, data = df_1)\n# summary(anova_model)\ntable_anova <- model_parameters(anova_model)\n\n# report the model\nreport::report(anova_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nThe ANOVA (formula: y ~ group) suggests that:\n\n  - The main effect of group is statistically significant and large (F(2, 87) =\n689.11, p < .001; Eta2 = 0.94, 95% CI [0.92, 1.00])\n\nEffect sizes were labelled following Field's (2013) recommendations.\n```\n\n\n:::\n:::\n\n\n\nNext, we analyse the same data using linear regression. In R, regression models automatically convert categorical variables into dummy variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# for tables (just installed)\nlibrary(parameters)\n\n# regression model \nfit <- lm(y ~ group, data = df_1)\n\n# uncomment if you want an ordinary summary\n# summary(regression_model)\n\ntable_fit <- parameters::model_parameters(fit)\n\n# print table\ntable_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParameter   | Coefficient |   SE |           95% CI | t(87) |      p\n--------------------------------------------------------------------\n(Intercept) |      101.22 | 2.60 | [ 96.06, 106.39] | 38.98 | < .001\ngroup [2]   |       -0.80 | 3.67 | [ -8.10,   6.50] | -0.22 | 0.827 \ngroup [3]   |      117.67 | 3.67 | [110.37, 124.97] | 32.04 | < .001\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(parameters)\nlibrary(report)\n\n# report the model\nreport_fit <- report_parameters(fit)\n\n#print\nreport_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - The intercept is statistically significant and positive (beta = 101.22, 95% CI [96.06, 106.39], t(87) = 38.98, p < .001; Std. beta = -0.68, 95% CI [-0.76, -0.59])\n  - The effect of group [2] is statistically non-significant and negative (beta = -0.80, 95% CI [-8.10, 6.50], t(87) = -0.22, p = 0.827; Std. beta = -0.01, 95% CI [-0.14, 0.11])\n  - The effect of group [3] is statistically significant and positive (beta = 117.67, 95% CI [110.37, 124.97], t(87) = 32.04, p < .001; Std. beta = 2.04, 95% CI [1.91, 2.17])\n```\n\n\n:::\n:::\n\n\n\n## Upshot\n\nANOVA partitions variance into between-group and within-group components, while regression models the mean of the dependent variable as a linear function of the independent (including categorical) variables. For many questions, ANOVA is appropriate, however, when we are comparing groups, we often want a finer-grained interpretation. Regression is built for obtaining this finer grain understanding. We will return to regression over the next few weeks and use regression to hone your skills in R. Later, Along the way, you'll learn more about data visualisation, modelling, and reporting.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# graph the output of the parameters table\n# visualisation\nplot(table_fit)\n```\n\n::: {.cell-output-display}\n![](01-content_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n### Exercise 3\n\nPerform a linear regression analysis using R. Follow the detailed instructions below to simulate the necessary data, execute the regression, and report your findings:\n\n1. **Simulate Data:**\n   - Generate two continuous variables, `Y` and `A`, with `n = 100` observations each.\n   - The variable `A` should have a mean of `50` and a standard deviation (`sd`) of `10`.\n\n2. **Define the Relationship:**\n   - Simulate the variable `Y` such that it is linearly related to `A` with a specified effect size. The effect size of `A` on `Y` must be explicitly defined as `2`.\n\n3. **Incorporate an Error Term:**\n   - When simulating `Y`, include an error term with a standard deviation (`sd`) of `20` to introduce variability.\n\n4. **Regression Analysis:**\n   - Use the `lm()` function in R to regress `Y` on `A`.\n   - Ensure the regression model captures the specified effect of `A` on `Y`.\n\n5. **Report the Results:**\n   - Output the regression model summary to examine the coefficients, including the effect of `A` on `Y`, and assess the model's overall fit and significance.\n\n\n## For more information about packages\n\n[ggplot2](https://ggplot2.tidyverse.org/)\n[Parameters package](https://easystats.github.io/parameters/)\n[Report package](https://easystats.github.io/report/index.html)\n\n\n## Further Information on Packages\n\nFor comprehensive details and resources on specific packages, visit the following links:\n\n  - [ggplot2](https://ggplot2.tidyverse.org/): A system for declaratively creating graphics, based on The Grammar of Graphics.\n\n  - [Parameters package](https://easystats.github.io/parameters/): Provides utilities for processing model parameters and their metrics.\n\n  - [Report package](https://easystats.github.io/report/index.html): Facilitates the automated generation of reports from statistical models.\n\n\n\n\n## Here is what you have learned\n\n- **How to install and setup R:** \n\nYou've successfully installed R and RStudio, setting up your workstation for statistical analysis.\n  \n- **How to install and use RStudio:** \n\nYou've familiarised yourself with the RStudio interface, including the console, source editor, environment tab, and other utilities for effective data analysis.\n  \n- **Basic R operations:** \n\nYou've practided using R for basic arithmetic operations, understanding how to execute simple commands in the console.\n  \n- **Data simulation:** \n\nYou've learned to simulate datasets in R. This is a foundational skill for exploring statistical concepts and data manipulation techniques. Congratulations! \n  \n- **Data visualisation:** \n\nYou've begun data visualising data through boxplots and histograms and coefficient plots, which is crucial for analysing and communicating statistical findings.\n  \n- **Statistical tests:** You've conducted basic statistical tests, including t-tests and ANOVA, gaining insights into comparing means across groups.\n  \n- **Understanding ANOVA and regression:** \n\nYou've explored the equivalence of ANOVA and regression analysis, learning how these methods can be applied to analyse and interpret data effectively.\n\n\n\n\n\n\n## Getting Help \n\nAs sure as night follows day, you will need help coding.  Key resources\n\n1. **Large Language Models (LLMs):** OpenAI's premium LLM (GPT-4) outperforms the free version (GPT-3.5) for complex queries. \n\n2. **Stack Exchange:** a valuable resource for coding advice and solutions.\n\n3. **Developer Websites and GitHub Pages:** Directly engage with package developers and the community for insights and support.[Parameters package discussion page](https://github.com/easystats/parameters/discussions) offers insights and support directly from its developers and user community.\n\n4.  Your tutors and lecturer. We care. We’re here to help you. \n\n\n## Recommended Reading\n\n- Wickham, H., & Grolemund, G. (2016). *R for Data Science*. O'Reilly Media. [Available online](https://r4ds.had.co.nz\n\n\n## Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(report)\nreport::cite_packages()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Arel-Bundock V (2024). _marginaleffects: Predictions, Comparisons, Slopes, Marginal Means, and Hypothesis Tests_. R package version 0.18.0, <https://CRAN.R-project.org/package=marginaleffects>.\n  - Barrett M (2021). _ggokabeito: 'Okabe-Ito' Scales for 'ggplot2' and 'ggraph'_. R package version 0.1.0, <https://CRAN.R-project.org/package=ggokabeito>.\n  - Bates D, Mächler M, Bolker B, Walker S (2015). \"Fitting Linear Mixed-Effects Models Using lme4.\" _Journal of Statistical Software_, *67*(1), 1-48. doi:10.18637/jss.v067.i01 <https://doi.org/10.18637/jss.v067.i01>.\n  - Bates D, Maechler M, Jagan M (2024). _Matrix: Sparse and Dense Matrix Classes and Methods_. R package version 1.6-5, <https://CRAN.R-project.org/package=Matrix>.\n  - Bengtsson H (2021). \"A Unifying Framework for Parallel and Distributed Processing in R using Futures.\" _The R Journal_, *13*(2), 208-227. doi:10.32614/RJ-2021-048 <https://doi.org/10.32614/RJ-2021-048>, <https://doi.org/10.32614/RJ-2021-048>.\n  - Bengtsson H (2021). \"A Unifying Framework for Parallel and Distributed Processing in R using Futures.\" _The R Journal_, *13*(2), 208-227. doi:10.32614/RJ-2021-048 <https://doi.org/10.32614/RJ-2021-048>, <https://doi.org/10.32614/RJ-2021-048>.\n  - Bengtsson H (2023). _progressr: An Inclusive, Unifying API for Progress Updates_. R package version 0.14.0, <https://CRAN.R-project.org/package=progressr>.\n  - Blair G, Cooper J, Coppock A, Humphreys M, Bicalho C, Fultz N, Medina L (2021). _DesignLibrary: Library of Research Designs_. R package version 0.1.10, <https://CRAN.R-project.org/package=DesignLibrary>.\n  - Blair G, Cooper J, Coppock A, Humphreys M, Rudkin A, Fultz N (2024). _fabricatr: Imagine Your Data Before You Collect It_. R package version 1.0.2, <https://CRAN.R-project.org/package=fabricatr>.\n  - Blair G, Cooper J, Coppock A, Humphreys M, Sonnet L (2024). _estimatr: Fast Estimators for Design-Based Inference_. R package version 1.0.2, <https://CRAN.R-project.org/package=estimatr>.\n  - Blair G, Coppock A, Humphreys M (2023). _Research Design in the Social Sciences: Declaration, Diagnosis, and Redesign_. Princeton University Press, Princeton. <https://book.declaredesign.org>. Blair G, Cooper J, Coppock A, Humphreys M (2019). \"Declaring and Diagnosing Research Designs.\" _American Political Science Review_, *113*, 838-859. <https://declaredesign.org/paper.pdf>.\n  - Brown C (2018). _formula.tools: Programmatic Utilities for Manipulating Formulas, Expressions, Calls, Assignments and Other R Objects_. R package version 1.7.1, <https://CRAN.R-project.org/package=formula.tools>.\n  - Chang W (2023). _extrafont: Tools for Using Fonts_. R package version 0.19, <https://CRAN.R-project.org/package=extrafont>.\n  - Chen T, He T, Benesty M, Khotilovich V, Tang Y, Cho H, Chen K, Mitchell R, Cano I, Zhou T, Li M, Xie J, Lin M, Geng Y, Li Y, Yuan J (2024). _xgboost: Extreme Gradient Boosting_. R package version 1.7.7.1, <https://CRAN.R-project.org/package=xgboost>.\n  - Christopher H. Jackson (2011). \"Multi-State Models for Panel Data: The msm Package for R.\" _Journal of Statistical Software_, *38*(8), 1-29. doi:10.18637/jss.v038.i08 <https://doi.org/10.18637/jss.v038.i08>.\n  - Coppock A (2023). _randomizr: Easy-to-Use Tools for Common Forms of Random Assignment and Sampling_. R package version 1.0.0, <https://CRAN.R-project.org/package=randomizr>.\n  - Csárdi G, Hester J, Wickham H, Chang W, Morgan M, Tenenbaum D (2023). _remotes: R Package Installation from Remote Repositories, Including 'GitHub'_. R package version 2.4.2.1, <https://CRAN.R-project.org/package=remotes>.\n  - Eddelbuettel D, Francois R, Allaire J, Ushey K, Kou Q, Russell N, Ucar I, Bates D, Chambers J (2024). _Rcpp: Seamless R and C++ Integration_. R package version 1.0.12, <https://CRAN.R-project.org/package=Rcpp>. Eddelbuettel D, François R (2011). \"Rcpp: Seamless R and C++ Integration.\" _Journal of Statistical Software_, *40*(8), 1-18. doi:10.18637/jss.v040.i08 <https://doi.org/10.18637/jss.v040.i08>. Eddelbuettel D (2013). _Seamless R and C++ Integration with Rcpp_. Springer, New York. doi:10.1007/978-1-4614-6868-4 <https://doi.org/10.1007/978-1-4614-6868-4>, ISBN 978-1-4614-6867-7. Eddelbuettel D, Balamuta J (2018). \"Extending R with C++: A Brief Introduction to Rcpp.\" _The American Statistician_, *72*(1), 28-36. doi:10.1080/00031305.2017.1375990 <https://doi.org/10.1080/00031305.2017.1375990>.\n  - Firke S (2023). _janitor: Simple Tools for Examining and Cleaning Dirty Data_. R package version 2.2.0, <https://CRAN.R-project.org/package=janitor>.\n  - Fong C, Ratkovic M, Imai K (2022). _CBPS: Covariate Balancing Propensity Score_. R package version 0.23, <https://CRAN.R-project.org/package=CBPS>.\n  - Freedman Ellis G, Schneider B (2023). _srvyr: 'dplyr'-Like Syntax for Summary Statistics of Survey Data_. R package version 1.2.0, <https://CRAN.R-project.org/package=srvyr>.\n  - Friedman J, Tibshirani R, Hastie T (2010). \"Regularization Paths for Generalized Linear Models via Coordinate Descent.\" _Journal of Statistical Software_, *33*(1), 1-22. doi:10.18637/jss.v033.i01 <https://doi.org/10.18637/jss.v033.i01>. Simon N, Friedman J, Tibshirani R, Hastie T (2011). \"Regularization Paths for Cox's Proportional Hazards Model via Coordinate Descent.\" _Journal of Statistical Software_, *39*(5), 1-13. doi:10.18637/jss.v039.i05 <https://doi.org/10.18637/jss.v039.i05>. Tay JK, Narasimhan B, Hastie T (2023). \"Elastic Net Regularization Paths for All Generalized Linear Models.\" _Journal of Statistical Software_, *106*(1), 1-31. doi:10.18637/jss.v106.i01 <https://doi.org/10.18637/jss.v106.i01>.\n  - Gilbert P, Varadhan R (2019). _numDeriv: Accurate Numerical Derivatives_. R package version 2016.8-1.1, <https://CRAN.R-project.org/package=numDeriv>.\n  - Greifer N (2023). _WeightIt: Weighting for Covariate Balance in Observational Studies_. R package version 0.14.2, <https://CRAN.R-project.org/package=WeightIt>.\n  - Greifer N (2024). _cobalt: Covariate Balance Tables and Plots_. R package version 4.5.3, <https://CRAN.R-project.org/package=cobalt>.\n  - Greifer N, Worthington S, Iacus S, King G (2023). _clarify: Simulation-Based Inference for Regression Models_. R package version 0.2.0, <https://CRAN.R-project.org/package=clarify>.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\" _Journal of Statistical Software_, *40*(3), 1-25. <https://www.jstatsoft.org/v40/i03/>.\n  - Halekoh U, Højsgaard S, Yan J (2006). \"The R Package geepack for Generalized Estimating Equations.\" _Journal of Statistical Software_, *15/2*, 1-11. Yan J, Fine JP (2004). \"Estimating Equations for Association Structures.\" _Statistics in Medicine_, *23*, 859-880. Yan J (2002). \"geepack: Yet Another Package for Generalized Estimating Equations.\" _R-News_, *2/3*, 12-14.\n  - Hansen BB, Klopfer SO (2006). \"Optimal full matching and related designs via network flows.\" _Journal of Computational and Graphical Statistics_, *15*(3), 609-627.\n  - Hastie SMDfmbT, wrapper. RTUAMFuwTLl (2023). _earth: Multivariate Adaptive Regression Splines_. R package version 5.3.2, <https://CRAN.R-project.org/package=earth>.\n  - Helske S, Helske J (2019). \"Mixture Hidden Markov Models for Sequence Data: The seqHMM Package in R.\" _Journal of Statistical Software_, *88*(3), 1-32. doi:10.18637/jss.v088.i03 <https://doi.org/10.18637/jss.v088.i03>. Helske J, Helske S (2023). _seqHMM: Mixture hidden Markov models for social sequence data and other multivariate, multichannel categorical time series_. R package version 1.2.6, <https://cran.r-project.org/package=seqHMM>.\n  - Henry L, Wickham H (2024). _rlang: Functions for Base Types and Core R and 'Tidyverse' Features_. R package version 1.1.3, <https://CRAN.R-project.org/package=rlang>.\n  - Hester J, Bryan J (2024). _glue: Interpreted String Literals_. R package version 1.7.0, <https://CRAN.R-project.org/package=glue>.\n  - Hester J, Wickham H, Csárdi G (2023). _fs: Cross-Platform File System Operations Based on 'libuv'_. R package version 1.6.3, <https://CRAN.R-project.org/package=fs>.\n  - Ho D, Imai K, King G, Stuart E (2011). \"MatchIt: Nonparametric Preprocessing for Parametric Causal Inference.\" _Journal of Statistical Software_, *42*(8), 1-28. doi:10.18637/jss.v042.i08 <https://doi.org/10.18637/jss.v042.i08>.\n  - Honaker J, King G, Blackwell M (2011). \"Amelia II: A Program for Missing Data.\" _Journal of Statistical Software_, *45*(7), 1-47. doi:10.18637/jss.v045.i07 <https://doi.org/10.18637/jss.v045.i07>.\n  - Iannone R, Cheng J, Schloerke B, Hughes E, Lauer A, Seo J (2024). _gt: Easily Create Presentation-Ready Display Tables_. R package version 0.10.1, <https://CRAN.R-project.org/package=gt>.\n  - J L (2006). \"Plotrix: a package in the red light district of R.\" _R-News_, *6*(4), 8-12.\n  - Kassambara A (2023). _ggpubr: 'ggplot2' Based Publication Ready Plots_. R package version 0.6.0, <https://CRAN.R-project.org/package=ggpubr>.\n  - Kay M (2024). \"ggdist: Visualizations of Distributions and Uncertainty in the Grammar of Graphics.\" _IEEE Transactions on Visualization and Computer Graphics_, 1-11. doi:10.1109/TVCG.2023.3327195 <https://doi.org/10.1109/TVCG.2023.3327195>. Kay M (2023). _ggdist: Visualizations of Distributions and Uncertainty_. doi:10.5281/zenodo.3879620 <https://doi.org/10.5281/zenodo.3879620>, R package version 3.3.1, <https://mjskay.github.io/ggdist/>.\n  - Lüdecke D (2018). \"ggeffects: Tidy Data Frames of Marginal Effects from Regression Models.\" _Journal of Open Source Software_, *3*(26), 772. doi:10.21105/joss.00772 <https://doi.org/10.21105/joss.00772>.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing and Exploring the Parameters of Statistical Models using R.\" _Journal of Open Source Software_, *5*(53), 2445. doi:10.21105/joss.02445 <https://doi.org/10.21105/joss.02445>.\n  - Lumley T (2023). \"survey: analysis of complex survey samples.\" R package version 4.2. Lumley T (2004). \"Analysis of Complex Survey Samples.\" _Journal of Statistical Software_, *9*(1), 1-19. R package verson 2.2. Lumley T (2010). _Complex Surveys: A Guide to Analysis Using R: A Guide to Analysis Using R_. John Wiley and Sons.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023). \"Automated Results Reporting as a Practical Tool to Improve Reproducibility and Methodological Best Practices Adoption.\" _CRAN_. <https://easystats.github.io/report/>.\n  - Milborrow S (2022). _plotmo: Plot a Model's Residuals, Response, and Partial Dependence Plots_. R package version 3.6.2, <https://CRAN.R-project.org/package=plotmo>.\n  - Mullen KM, van Stokkum IHM (2023). _nnls: The Lawson-Hanson Algorithm for Non-Negative Least Squares (NNLS)_. R package version 1.5, <https://CRAN.R-project.org/package=nnls>.\n  - Müller K (2020). _here: A Simpler Way to Find Your Files_. R package version 1.0.1, <https://CRAN.R-project.org/package=here>.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version 3.2.1, <https://CRAN.R-project.org/package=tibble>.\n  - Ooms J (2022). _katex: Rendering Math to HTML, 'MathML', or R-Documentation Format_. R package version 1.4.1, <https://CRAN.R-project.org/package=katex>.\n  - Ooms J (2023). _pdftools: Text Extraction, Rendering and Converting of PDF Documents_. R package version 3.4.0, <https://CRAN.R-project.org/package=pdftools>.\n  - Pedersen T (2024). _patchwork: The Composer of Plots_. R package version 1.2.0, <https://CRAN.R-project.org/package=patchwork>.\n  - Pishgar F, Greifer N, Leyrat C, Stuart E (2021). \"MatchThem:: Matching and Weighting after Multiple Imputation.\" _The R Journal_. doi:10.32614/RJ-2021-073 <https://doi.org/10.32614/RJ-2021-073>, <https://journal.r-project.org/archive/2021/RJ-2021-073/>.\n  - Polley E, LeDell E, Kennedy C, van der Laan M (2023). _SuperLearner: Super Learner Prediction_. R package version 2.0-29-9000, <https://github.com/ecpolley/SuperLearner>.\n  - R Core Team (2023). _R: A Language and Environment for Statistical Computing_. R Foundation for Statistical Computing, Vienna, Austria. <https://www.R-project.org/>.\n  - Rich B (2023). _table1: Tables of Descriptive Statistics in HTML_. R package version 1.4.3, <https://CRAN.R-project.org/package=table1>.\n  - Richardson N, Cook I, Crane N, Dunnington D, François R, Keane J, Moldovan-Grünfeld D, Ooms J, Wujciak-Jens J, Apache Arrow (2023). _arrow: Integration to 'Apache' 'Arrow'_. R package version 14.0.0.2, <https://CRAN.R-project.org/package=arrow>.\n  - Robinson D, Hayes A, Couch S (2023). _broom: Convert Statistical Objects into Tidy Tibbles_. R package version 1.0.5, <https://CRAN.R-project.org/package=broom>.\n  - Robitzsch A, Grund S (2024). _miceadds: Some Additional Multiple Imputation Functions, Especially for 'mice'_. R package version 3.17-44, <https://CRAN.R-project.org/package=miceadds>.\n  - Shi B, Choirat C, Valeri L (2023). _CMAverse: Causal Mediation Analysis_. R package version 0.1.0, https://github.com/BS1125/CMAverse, <https://bs1125.github.io/CMAverse/>.\n  - Sjoberg D, Whiting K, Curry M, Lavery J, Larmarange J (2021). \"Reproducible Summary Tables with the gtsummary Package.\" _The R Journal_, *13*, 570-580. doi:10.32614/RJ-2021-053 <https://doi.org/10.32614/RJ-2021-053>, <https://doi.org/10.32614/RJ-2021-053>.\n  - Sjolander A, Dahlqwist E (2021). _stdReg: Regression Standardization_. R package version 3.4.1, <https://CRAN.R-project.org/package=stdReg>.\n  - Snow G (2024). _TeachingDemos: Demonstrations for Teaching and Learning_. R package version 2.13, <https://CRAN.R-project.org/package=TeachingDemos>.\n  - Spina A, Kamvar Z, Schumacher D (2024). _epikit: Miscellaneous Helper Tools for Epidemiologists_. R package version 0.1.6, <https://CRAN.R-project.org/package=epikit>.\n  - Therneau T (2024). _A Package for Survival Analysis in R_. R package version 3.5-8, <https://CRAN.R-project.org/package=survival>. Terry M. Therneau, Patricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_. Springer, New York. ISBN 0-387-98784-3.\n  - Tibshirani J, Athey S, Sverdrup E, Wager S (2024). _grf: Generalized Random Forests_. R package version 2.3.1, <https://github.com/grf-labs/grf>.\n  - Tierney N, Cook D (2023). \"Expanding Tidy Data Principles to Facilitate Missing Data Exploration, Visualization and Assessment of Imputations.\" _Journal of Statistical Software_, *105*(7), 1-31. doi:10.18637/jss.v105.i07 <https://doi.org/10.18637/jss.v105.i07>.\n  - van Buuren S, Groothuis-Oudshoorn K (2011). \"mice: Multivariate Imputation by Chained Equations in R.\" _Journal of Statistical Software_, *45*(3), 1-67. doi:10.18637/jss.v045.i03 <https://doi.org/10.18637/jss.v045.i03>.\n  - van der Wal WM, Geskus RB (2011). \"ipw: An R Package for Inverse Probability Weighting.\" _Journal of Statistical Software_, *43*(13), 1-23. doi:10.18637/jss.v043.i13 <https://doi.org/10.18637/jss.v043.i13>.\n  - VanderWeele TJ, Ding P (2011). \"Sensitivity analysis in observational research: introducing the E-value.\" _Annals of Internal Medicine_, *167*(4), 268-274. Mathur MB, VanderWeele TJ (2019). \"Sensitivity analysis for unmeasured confounding in meta-analyses.\" _Journal of the American Statistical Association>_. Smith LH, VanderWeele TJ (2019). \"Bounding bias due to selection.\" _Epidemiology_.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth edition. Springer, New York. ISBN 0-387-95457-0, <https://www.stats.ox.ac.uk/pub/MASS4/>.\n  - Venables WN, Ripley BD (2002). _Modern Applied Statistics with S_, Fourth edition. Springer, New York. ISBN 0-387-95457-0, <https://www.stats.ox.ac.uk/pub/MASS4/>.\n  - Waring E, Quinn M, McNamara A, Arino de la Rubia E, Zhu H, Ellis S (2022). _skimr: Compact and Flexible Summaries of Data_. R package version 2.1.5, <https://CRAN.R-project.org/package=skimr>.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_. Springer-Verlag New York. ISBN 978-3-319-24277-4, <https://ggplot2.tidyverse.org>.\n  - Wickham H (2023). _conflicted: An Alternative Conflict Resolution Strategy_. R package version 1.2.0, <https://CRAN.R-project.org/package=conflicted>.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables (Factors)_. R package version 1.0.0, <https://CRAN.R-project.org/package=forcats>.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String Operations_. R package version 1.5.1, <https://CRAN.R-project.org/package=stringr>.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686. doi:10.21105/joss.01686 <https://doi.org/10.21105/joss.01686>.\n  - Wickham H, Bryan J, Barrett M, Teucher A (2024). _usethis: Automate Package and Project Setup_. R package version 2.2.3, <https://CRAN.R-project.org/package=usethis>.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar of Data Manipulation_. R package version 1.1.4, <https://CRAN.R-project.org/package=dplyr>.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package version 1.0.2, <https://CRAN.R-project.org/package=purrr>.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. R package version 2.1.5, <https://CRAN.R-project.org/package=readr>.\n  - Wickham H, Hester J, Chang W, Bryan J (2022). _devtools: Tools to Make Developing R Packages Easier_. R package version 2.4.5, <https://CRAN.R-project.org/package=devtools>.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package version 1.3.1, <https://CRAN.R-project.org/package=tidyr>.\n  - Williams N, Díaz I (2023). \"lmtp: An R package for estimating the causal effects of modified treatment policies.\" _Observational Studies_. <https://muse.jhu.edu/article/883479>. Díaz I, Williams N, Hoffman K, Schneck E (2021). \"Non-parametric causal effects based on longitudinal modified treatment policies.\" _Journal of the American Statistical Association_. doi:10.1080/01621459.2021.1955691 <https://doi.org/10.1080/01621459.2021.1955691>.\n  - Wright MN, Ziegler A (2017). \"ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R.\" _Journal of Statistical Software_, *77*(1), 1-17. doi:10.18637/jss.v077.i01 <https://doi.org/10.18637/jss.v077.i01>.\n  - Xie Y (2023). _knitr: A General-Purpose Package for Dynamic Report Generation in R_. R package version 1.45, <https://yihui.org/knitr/>. Xie Y (2015). _Dynamic Documents with R and knitr_, 2nd edition. Chapman and Hall/CRC, Boca Raton, Florida. ISBN 978-1498716963, <https://yihui.org/knitr/>. Xie Y (2014). \"knitr: A Comprehensive Tool for Reproducible Research in R.\" In Stodden V, Leisch F, Peng RD (eds.), _Implementing Reproducible Computational Research_. Chapman and Hall/CRC. ISBN 978-1466561595.\n  - Xie Y (2023). _tinytex: Helper Functions to Install and Maintain TeX Live, and Compile LaTeX Documents_. R package version 0.49, <https://github.com/rstudio/tinytex>. Xie Y (2019). \"TinyTeX: A lightweight, cross-platform, and easy-to-maintain LaTeX distribution based on TeX Live.\" _TUGboat_, *40*(1), 30-32. <https://tug.org/TUGboat/Contents/contents40-1.html>.\n  - Zeileis A, Croissant Y (2010). \"Extended Model Formulas in R: Multiple Parts and Multiple Responses.\" _Journal of Statistical Software_, *34*(1), 1-13. doi:10.18637/jss.v034.i01 <https://doi.org/10.18637/jss.v034.i01>.\n  - Zeileis A, Köll S, Graham N (2020). \"Various Versatile Variances: An Object-Oriented Implementation of Clustered Covariances in R.\" _Journal of Statistical Software_, *95*(1), 1-36. doi:10.18637/jss.v095.i01 <https://doi.org/10.18637/jss.v095.i01>. Zeileis A (2004). \"Econometric Computing with HC and HAC Covariance Matrix Estimators.\" _Journal of Statistical Software_, *11*(10), 1-17. doi:10.18637/jss.v011.i10 <https://doi.org/10.18637/jss.v011.i10>. Zeileis A (2006). \"Object-Oriented Computation of Sandwich Estimators.\" _Journal of Statistical Software_, *16*(9), 1-16. doi:10.18637/jss.v016.i09 <https://doi.org/10.18637/jss.v016.i09>.\n  - Zhu H (2024). _kableExtra: Construct Complex Table with 'kable' and Pipe Syntax_. R package version 1.4.0, <https://CRAN.R-project.org/package=kableExtra>.\n```\n\n\n:::\n:::\n\n\n\n\n## Appendix A: Solutions to Problem Sets {#appendix-a}\n\n\n\n### Solution Problem Set 3: simulate data and regression reporting \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(parameters)\n#  seed for reproducibility\nset.seed(12345)\n\n# number of observations\nn <- 100\n\n# simulate data for variable A with specified mean and sd\nA <- rnorm(n, mean = 50, sd = 10)\n\n# define the specified effect size of A on Y\nbeta_A <- 2\n\n\n# simulate data and make data frame in one step\n\ndf_3 <- data.frame(\n  # simulate data for variable A with specified mean and sd\n  A =  rnorm(n, mean = 50, sd = 10),\n  Y = 5 + beta_A * A + rnorm(n, mean = 0, sd = 20)\n)\n\n# view\nhead(df_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         A         Y\n1 52.23925  87.98766\n2 38.43777 106.60413\n3 54.22419 107.68437\n4 36.75245 117.09730\n5 51.41084 133.74473\n6 44.63952  70.74512\n```\n\n\n:::\n\n```{.r .cell-code}\nstr(df_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t100 obs. of  2 variables:\n $ A: num  52.2 38.4 54.2 36.8 51.4 ...\n $ Y: num  88 107 108 117 134 ...\n```\n\n\n:::\n\n```{.r .cell-code}\n# Perform linear regression of Y on A\n\nfit_3 <- lm(Y ~ A, data = df_3)\n\n# Report the results of the regression\n# summary(model)\n\n# report\nparameters::model_parameters(fit_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParameter   | Coefficient |    SE |          95% CI | t(98) |      p\n--------------------------------------------------------------------\n(Intercept) |      109.17 | 14.62 | [80.17, 138.18] |  7.47 | < .001\nA           |   -3.80e-03 |  0.28 | [-0.57,   0.56] | -0.01 | 0.989 \n```\n\n\n:::\n\n```{.r .cell-code}\nreport(fit_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWe fitted a linear model (estimated using OLS) to predict Y with A (formula: Y\n~ A). The model explains a statistically not significant and very weak\nproportion of variance (R2 = 1.83e-06, F(1, 98) = 1.79e-04, p = 0.989, adj. R2\n= -0.01). The model's intercept, corresponding to A = 0, is at 109.17 (95% CI\n[80.17, 138.18], t(98) = 7.47, p < .001). Within this model:\n\n  - The effect of A is statistically non-significant and negative (beta =\n-3.80e-03, 95% CI [-0.57, 0.56], t(98) = -0.01, p = 0.989; Std. beta =\n-1.35e-03, 95% CI [-0.20, 0.20])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n```\n\n\n:::\n:::\n\n\n\n## Appendix B: I lied\n\nWe can get group comparisons with ANOVA, for example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Conduct Tukey's HSD test for post-hoc comparisons\ntukey_post_hoc <- TukeyHSD(anova_model)\n\n# Display the results\nprint(tukey_post_hoc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = y ~ group, data = df_1)\n\n$group\n           diff        lwr        upr     p adj\n2-1  -0.8030143  -9.560281   7.954253 0.9739971\n3-1 117.6732276 108.915961 126.430495 0.0000000\n3-2 118.4762419 109.718975 127.233509 0.0000000\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(tukey_post_hoc)\n```\n\n::: {.cell-output-display}\n![](01-content_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nRegression and ANOVA are equivalent\n\n\n\n",
    "supporting": [
      "01-content_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}