{
  "hash": "fe2651ac59c7282502d499a0575edb1b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Causal Inference: reconsidering measurement and selection biases\"\ndate: \"2023-MAY-16\"\n---\n\n\n\n\n  \n## Overview\n  \n\nRecall that psychology begings with a question about cognition and behavior. What do we want to know? Before all else, we must ask, and motivate this question. \n\nSuppose we have defined a question. How can we address it using observational data? \n\nThis is the topic of today's siminar.\n  \n  \n\n## How do we do causal estimation?\n\nThere are two steps to causal estimation:\n\n1. State a causal question\n2. Answer that question [Cite Hernan]\n\n\n\n## Step 1: State a causal question\n\nStating a causal question requires describing: a. outcome(s), b. exposure, c. measured confounders, d. (suspected) unmeasured confounders, e. scale of causal contrasts, f. target population for whom the inferences apply. \n\nWe consider each of these processes in turn.\n\n\n\n### a. Identify the outcome(s) of interest\n\nWe use *Y* to denote an outcome of interest. This is the \"effect\" of interest.  \n\n#### Consider:\n\n- The outcome might be binary (severely distressed/not severely distressed), continuous (the average of the sum of the indicators), or a rate variable (the sum of the indicators).\n- It is crucial to specify the units in which the outcome is measured. \n- Transforming the outcome into standard deviation units can be beneficial.\n- The outcome must occur after the exposure or treatment.\n- We must designate a time period within which the outcome occurs, e.g, \"the one-year effect of a treatment on well-being as measured by Kessler-6.\"\n- We may be interested in multiple outcomes. This is the rational behind outcomewide science [cite tyler]\n- We must remember that the outcome might be measured with error, that such errors may be affected by the treatment or correlated with the measurement error of the treatment. (A topic of future seminars, which we will set to the side for now)\n\n\nHere, imagine we are interested in understanding only one outcome in our study: well-being as measured by the Kessler-6 depression/anxiety scale. \n\n\n###  b. Define the exposure or intervention \n\nWe use *A* to denote the the exposure or treatment. This is the variable that we hypothesise might affect the outcome.  This variable denotes the cause of interest. We will restrict our focus to consider in which there is only one treatment (i.e. we will not consider complex multi-treatment regimes.)\n\nHere, imagine we are interested in understanding the causal effect of 'Church attendance'. \n\n#### Consider:\n\n- To affect *Y*, *A* must occur before *Y*. \n- What does *A* indicate?  We may characterise 'Church Attendance' as a binary exposure (attend/not attend) or as a continuous exposure (attend weekly/attend monthly). The exposure, in this instance, remains nebulous until we delineate the unit change in *A* we are interested in investigating.\n- For theoretical and practical purpose we might want to trunctate the variable into categories: (none/some; none/less than weekly, weekly or more)... Why? Because our causal question requires stating the contrast between the states of the world in which we are interested. Additionally, experts often make decisions on the basis of discrete thresholds (has risk of depression/does not).\n- We must remember that an exposure or treatment might be measured with error, that such errors might be correlated with the measurement error of the outcome or affect it. (Again, a topic of future seminars, which we will set to the side for now).\n\n\n### c. Identify pre-exposure covariates for confounding control\n\nWe use **L** to denote the set of measured baseline confounders of the the exposure-outcome association. For a three-wave panel design, we employ VanderWeele's modified disjunctive cause criterion, we advises: control for any covariate that is a cause of the exposure, the outcome, or both, excluding any instrumental variable and incorporating any proxy for an unmeasured variable that is a common cause of both the exposure and the outcome.\n\n#### Consider: \n\n  - To affect *Y*,  *L* must occur before *Y*.  \n  - To affect *A*, *L* must occur before *A*. \n  - Although we may gain precision by including an *L* that affects *Y* but is unrelated to *A*, including variables that occur after *A* will be hazardous if it is possible that *A* affects *L* (or its measurement).\n  - A useful  set of default counfounders in NZAVS studies is given in your workbooks. \n  - Note we have left out the concept of \"selection bias.\" There are indeed sources of bias that may occure after *A*. This is another topic for the week ahead. \n\n\n### d. Highlight unmeasured pre-treatment covariates\n\nLet **U** denoted unmeasured pre-treatment covariates that may potentially bias the statistical association between *A* and *Y* independently of the measured covariates. \n\n#### Consider:\n  - To affect *Y* and *A*, *U* must occur before *A*.\n  - It is useful to draw a causal diagramme to illustrate all potential sources of bias. \n  - Causal diagrammes are qualitative tools that require specialist expertise. We cannot typically obtain a causal graph from the data.\n  - A causal diagramme should include only as much information as is required to assess confounding. See @fig-dag-outcomewide for an example.\n  - Because we cannot ensure the absence of unmeasured confounders in observational settings, it is vital to conduct sensitivity analyses for the results. For sensitivity analyeses, we use E-values, a topic for a latter seminar. \n\n\n### Choose the scale for a causal contrast \n\nAverage causal effects can be inferred by contrasting the expected outcome when a population is exposed to an exposure level, $E[Y(A = a)]$, with the expected outcome under a different exposure level, $E[Y(A=a')]$. \n\nFor a binary treatment with levels $A=0$ and $A=1$, the Average Treatment Effect (ATE), on the difference scale, is expressed:\n\n$$ATE_{\\text{risk difference}} = E[Y(1)|L] - E[Y(0)|L]$$\n\nOn the risk ratio scale, the ATE is expressed:\n\n$$ATE_{\\text{risk ratio}} = \\frac{E[Y(1)|L]}{E[Y(0)|L]}$$\n\nOther effect scales, such as the incidence rate ratio, incidence rate difference, or hazard ratio, might also be of interest. We can also define the Average Treatment Effect on the Treated (ATT) : \n\n$$ATT_{\\text{risk difference}} = E[Y(1) - Y(0)|A=1,L]$$\n\n$$ATT_{\\text{risk ratio}} = \\frac{E[Y(1)|A=1,L]}{E[Y(0)|A=1, L]}$$\n\n\nAnother common estimand is the Population Average Treatment Effect (PATE), which denotes the effect the treatment would have on the entire population if applied universally to that population. This quantity can be expressed:\n\n$$PATE_{\\text{risk difference}} = f(E[Y(1) - Y(0)|L], W)$$\n\n$$PATE_{\\text{risk ratio}} = f\\left(\\frac{E[Y(1)|L]}{E[Y(0)|L]}, W\\right)$$\n\nwhere $f$ is a function that incorporates weights $W$ into the estimation of the expected outcomes. These weights may correspond to the inverse probability of being sampled or in the case of NZAVS data, the survey weights are given from census estimates for the wider population.  Note: I will show you how to use weights in future seminars.\n\nWe might also be interested in identifying effects specific to certain strata, such as risk differences or risk ratios, as they are modified by baseline indicators.  Denote a stratum of interest by $S$. We may then compute: \n\n$$ATE_{S,\\text{risk difference}} = E[Y(1) - Y(0)|S, L]$$\n\n$$ATE_{S,\\text{risk ratio}} = \\frac{E[Y(1)|S, L]}{E[Y(0)|S, L]}$$\n\n\n#### Consider: \n\n- ** In this course, we are interested in stratum specific comparisons **\n- In the causal inference literature, the concept we use to make sense of stratum specific comparisons is called \"effect modification.\" \n- By inferring effects within stratums, we may evaluate whether the effects of different exposures or treatments on some well-defined outcome (measured in some well-defined time-period after the exposure) differ depending on group measurement. \n- The logic of effect modification differs from that of intereaction. \n\n\n\n\n#### Aside: extensions\n\nFor continuous exposures, we must stipulate the level of contrast for the exposure (e.g. weekly versus monthly church attendance):\n\n$$ATE_{A,A'} = E[Y(A) - Y(A')| L]$$\n\nThis essentially denotes an average treatment effect comparing the outcome under treatment level $A$ to the outcome under treatment level $A'$.\n\nLikewise:\n\n$$ATE_{A/A'} = \\frac{E[Y(A)| L]}{E[Y(A')| L]}$$\n\nThis defines the contrast of $A$ and $A'$ on a ratio scale. \n\n#### f. Describe the population(s) for whom the intended study is meant to generalise. \n\nThe potential outcomes literature in causal inference distinguishes between the concepts of generalisability and transportability. \n\n  - **Generalisability** refers to the ability to apply the causal effects estimated from a sample to the population it was drawn from. In simpler terms, it deals with the extrapolation of causal knowledge from a sample to the broader population. This concept is also called \"external validity\".  \n\n$$\\text{Generalizability} = PATE \\approx ATE_{\\text{sample}}$$\n\n  - **Transportability** refers to the ability to extrapolate causal effects learned from a source population to a target population when certain conditions are met. It deals with the transfer of causal knowledge across different settings or populations.\n\n$$\\text{Transportability} = ATE_{\\text{target}} \\approx f(ATE_{\\text{source}}, T)$$\n\nwhere $f$ is a function and $T$ is a function that maps the results from our source population to another population. To achieve transportability, we need information about the source and target populations and an understanding of how the relationships between treatment, outcome, and covariates differ between the populations. Assessing transportability requires scientific knowledge.\n\n### Summary Step 1: Consider how much we need to do when asking a causal question!\n\nWe discover that asking a causal question is a multifaceted task. It demands careful definition of the outcome, including its timing, the exposure, and covariates. It also requires selecting the appropriate scale for causal contrast, controlling for confounding, and potentially adjusting for sample weights or stratification. Finally, when asking a causal question, we must consider for whom the results apply. Only after following these steps can we then ask: \"How may we answer this causal question?\" \n\n\n## STEP 2: ANSWER A CAUSAL QUESTION\n\n#### Obtain longitudinal data\n\nNote that causal inference from observational data turns on the appropriate temporal ordering of the key variables involved in the study. \n\nRecall we have defined. \n\n- **A**: Our exposure or treatment variable, denoted as **A**.  Here we consider the example of 'Church attendance'.\n\n- **Y**: The outcome variable we are interested in, represented by **Y**, is psychological distress. We operationalise this variable through the 'Kessler-6' distress scale.\n\n- **L**: The confounding variables, collectively referred to as **L**, represent factors that can independently influence both **A** and **Y**. For example, socio-economic status could be a confounder that impacts both the likelihood of church attendance and the levels of psychological distress.\n\n\nGiven the importance of temporal ordering, we must now define time: \n\n\n- **t $\\in$ T**: Let $t$ denote within a multiwave panel study with **T** measurement intervals.\n  \nWhere $t/\\text{{exposure}}$ denotes the measurement interval for the exposure. Longitudinal data collection provides us the ability to establish a causal model such that: $t\\text{{baseline}}/\\mathbf{L} < t\\text{{exposure}}/\\text{{A}} < t\\text{{exposure}}/\\mathbf{Y}$.\n\nTo minimise the posibility of time-varying confounding and obtain the clearest effect estimates, we should acquire the most recent values of $\\mathbf{L}$ preceding $A$ and the latest values of $A$ before $Y$ such that: $t\\text{{0}}/\\mathbf{L} < t\\text{{1}}/\\text{{A}} < t\\text{{2}}/\\mathbf{Y}$. \n\n\n### Include the measured outcome with baseline covariates\n\nControlling for previous outcome is crucial because the outcome at baseline is often the most potent confounder of both the exposure post-exposure-outcome association. \n\n### Include the measured exposure with baseline covariates\n\nControlling for prior exposure enables the interpretation of the effect estimate as a change in the exposure in a manner akin to a randomised trial. We propose that the effect estimate with prior control for the exposure estimates the \"incidence exposure\" rather than the \"prevalence exposure\" [Hernan Danaei, Tavakkoli and Hernán, 2012, Hernán, 2015]. It is crucial to estimate the incidence exposure because if the effects of an exposure are harmful in the short term such that these effects are not subsequently measured, a failure to adjust for prior exposure will yield the illusion that the exposure is beneficial. Furthermore, this approach aids in controlling for unmeasured confounding. For such a confounder to dismiss the observed exposure-outcome association, it would need to do so independently of the prior level of the exposure and outcome.\n\n### State the eligibility criteria for participation\n\nThis step is invaluable for assessing whether we are answering the causal question that we have asked. \n\n#### Consider: \n\n  - Generalisability: we cannot evaluate inferences to a target group from the source popuation if we do not describe the source population\n  - Eligibility criteria will help us to ensure whether we have correctly evaluated potential measurement bias/error in our instruments.\n\n For example, the New Zealand Attitudes and Values Study is a National Probability study of New Zealanders. The details provided in the supplementary materials describe how individuals were randomly selected from the country's electoral roll. From these invitations there was typically less than 15% response rate. How might this process of recruitment affect generalisability and transportability of our results? \n\n  - (Aside: discuss per protocol effects/ intention to treat effects) \n\n### Handling of missing data \n\n  - As we will consider in the upcoming weeks, loss to follow up and non-response opens sources for bias. We must develop a strategy for handling missing data. \n  \n\n### State a statistical model  \n\nThe models we have considered in this course are G-computation, Inverse Probability of Treatement Weighting, and Doubly-Robust estimation.  \n:\n\n#### **G-computation for Subgroup Analysis Algorithm**\n\n**Step 1** Estimate the outcome model. Fit a model for the outcome $Y$, conditional on both the exposure $A$, the covariates $L$, and subgroup indicator $G$. This model can be linear regression, logistic regression, or another statistical model. The goal is to capture the relationship between the outcome, exposure, confounders, and subgroups.\n\n$$ E(Y|A,L,G) = f_Y(A,L,G; \\theta_Y) $$ \n\nThis equation represents the expected value of the outcome $Y$ given the exposure $A$, covariates $L$, and subgroup $G$ as modeled by the function $f_Y$ with parameters $\\theta_Y$. This formulation allows for the prediction of the average outcome $Y$ given certain values of $A$, $L$, and $G$. \n\n**Step 2** Simulate potential outcomes. For each individual $i$ in each subgroup $g$, predict their potential outcome $\\hat{Y}_{i,g}(a)$ under the intervention $A=a$, and $\\hat{Y}_{i,g}(a^{\\prime})$ under the intervention $A=a^{\\prime}$, using the estimated outcome model. This is done by replacing the observed value of the exposure $A$ in the outcome model with the counterfactual exposure values $a$ and $a^{\\prime}$, while keeping the values of the covariates $L$ and subgroup $G$ unchanged:\n\n\\[\\hat{Y}_{i,g}(a) = E[Y|A=a,L_i,G=g; \\theta_Y]\\]\n\n\\[\\hat{Y}_{i,g}(a^{\\prime}) = E[Y|A=a^{\\prime},L_i,G=g; \\theta_Y]\\]\n\nThis step involves simulating the outcomes under each intervention level for every individual within each subgroup, as if they were exposed to treatment level $a$ or $a^{\\prime}$. \n\n**Step 3** Estimate the average causal effect for each subgroup. Compute the expected value of the potential outcomes under each intervention level for each subgroup $g$:\n\n\\[E[Y(a)|G=g] = \\frac{1}{N_g}\\sum_{G_i=g}^N \\hat{Y}_{i,g}(a)\\]\n\n\\[E[Y(a^{\\prime})|G=g] = \\frac{1}{N_g}\\sum_{G_i=g}^N \\hat{Y}_{i,g}(a^{\\prime})\\]\n\nand calculate the difference for each subgroup $g$:\n\n\\[\\delta_g = E[Y(a)|G=g] - E[Y(a^{\\prime})|G=g]\\]\n\nThis difference represents the average causal effect of changing the exposure from level $a^{\\prime}$ to level $a$ within subgroup $g$. \n\nTo obtain the standard errors and confidence intervals for the subgroup-specific causal effects, simulation-based inference methods, such as the clarify package[@greifer2023], can be used.\n\n\n\n\n### What we have not done\n\nWe have not addressed: \n  - measurement error. Our graphs do not incorporate it. \n  - selection bias\n  - Outcome-wide studies\n  - Sampling weights. \n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}