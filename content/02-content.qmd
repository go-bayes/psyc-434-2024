---
title: "Causal diagrams: Five Elementary Structures"
date: "2023-MAR-04"
bibliography: /Users/joseph/GIT/templates/bib/references.bib
editor_options: 
  chunk_output_type: console
format:
  html:
    warnings: FALSE
    error: FALSE
    messages: FALSE
    code-overflow: scroll
    highlight-style: kate
    code-tools:
      source: true
      toggle: FALSE
html-math-method: katex
---

```{r}
#| echo: FALSE
#| warning: FALSE

# WARNING:  COMMENT THIS OUT. JB DOES THIS FOR WORKING WITHOUT WIFI
#source("/Users/joseph/GIT/templates/functions/libs2.R")

# WARNING:  COMMENT THIS OUT. JB DOES THIS FOR WORKING WITHOUT WIFI
#source("/Users/joseph/GIT/templates/functions/funs.R")

# ALERT: UNCOMMENT THIS AND DOWNLOAD THE FUNCTIONS FROM JB's GITHUB
# source(
#   "https://raw.githubusercontent.com/go-bayes/templates/main/functions/experimental_funs.R"
# )

# source(
#   "https://raw.githubusercontent.com/go-bayes/templates/main/functions/experimental_funs.R"
# )

# for making graphs
library("tinytex")
library("extrafont")
loadfonts(device = "all")
```

::: {.callout-note}
## Readings
- Barrett M (2023). _ggdag: Analyze and Create Elegant Directed Acyclic Graphs_. R package version 0.2.7.9000, <https://github.com/malcolmbarrett/ggdag>
- "An Introduction to Directed Acyclic Graphs", <https://r-causal.github.io/ggdag/articles/intro-to-dags.html>
- "Common Structures of Bias", <https://r-causal.github.io/ggdag/articles/bias-structures.html>
:::

::: {.callout-important}
## Key concepts for the test(s):
  - **Confounding**
  - **Causal Directed Acyclic Graph** 
  - **Five Elementary Causal Structures**
  - **d-separation**
  - **Four Rules of Confounding Control**
:::

::: {.callout-important}
## Download Your Laboratory R Script Here

Assuming you have installed R and RStudio:

1. Download the R script for Lab 01 by clicking the link below. This script contains the code you will work with during your laboratory session.

2. After downloading, open RStudio. 

3. In RStudio, create a new R script file by going to `File > New File > R Script`.

4. Create a new`.R` file called `02-lab.R` and provide your name, contact, data, and a brief title such as "Rimulating the basic five basic causal structures in R" 

Example: 

```{r}
#  Bob leBob
#  29 Feb 2024
#  bob@lebob.fr
#. Lab 02 - Simulating The Five Basic Structures of Cauality
```


5. Copy and paste the code chunks below from your computer onto the script during class. 


6. Save the new R script file in a clearly defined project directory folder for easy access during the lab.


7. Bring your computer to the lab.  
:::


## Part 1: Seminar


### Overview 

- Understand basic features of causal diagrams: definitions and applications
- Introduction to the five elementary causal structures
- Lab: Simulation and Regression


### Review

1. Psychological research begins with two questions: 

> 1. What do I want to know? 
> 2. For which population does this knowledge generalise?  

This course considers how to ask this psychological questions that pertain to populations with different characteristics 

2. In psychological research, we typically ask questions about the causes and consequences of thought and behaviour - "What if?" questions [@hernan2024WHATIF]. 

3. The following concepts help us to describe two distinct failure modes in psychological research when asking "What if?" questions:

  - **The Concept of External Validity**: the extent to which the findings of a study can be generalised to other situations, people, settings, and time periods. That is, we want to know if our findings carry beyond the *sample population* to the *target population*.  We fail when our results do not generalise as we think.  More fundamental, we fail when we have not clearly defined our question or our target population.

  - **The Concept of Internal Validity**: the extent to which the associations we obtain from data reflect causality. In psychological science, we use the terms "independent variable" and "dependent variable." Sometimes we use the terms "exogenous variable" and "endogenous variable."  Sometimes we use the term "predictor variable" to describe the "dependent" or "endogenous" variable. These words are confusing.  When asking "What if?" questions, we want to understand what would happen were we to intervene.  In this course, we will use the term "treatment" or equivalently the term "exposure" to denote the intervention; we will use the term "outcome" to denote the effect of an intervention.[^note]

[^note]: "What if?" questions implicitly invoke the idea of intervening on the world. "If we did *this*, *then* what would happen to *that*...?" Our preferred terminology reflects our interest in the effects of interventions.

5. During the first part of the course, our primary focus will be on challenges to internal validity from **confounding bias.**  


## Definitions

::: {#def-internal-validity}
We say internal validity is compromised if the association between the treatment and outcome in a study does not consistently reflect causality in the sample population as it is defined at baseline.
:::

::: {#def-external-validity}
We say external validity is compromised if the association between the treatment and outcome in a study does not consistently reflect causality in the target population as it is defined at baseline.
:::

The concept of "confounding bias" helps to clarify what it is at stake when evaluating the *internal validity* of a study.  As we shall see, there are several equivalent definitions of "confounding bias," which we will describe during the upcoming weeks. 

The definition of confounding bias that we will examine today is:

::: {#def-confounding}
We say there is confounding-bias if there is an open back-door path between the treatment and outcome, or if that path between the treatment and outcome is blocked.
:::

Today, our purpose will be to clarify the meaning of each term in this definition.  To that end, we will introduce the five elementary graphical structures and explain the four elementary rules that allow investigators to to move from the causal assumptions encoded in a causal diagram to an assessment of the challenges and opportunities for obtaining internal validity from data.


## Introduction to Causal Diagrams.

Causal diagrams, also called causal graphs, Directed Acyclic Graphs, and Causal Directed Acyclic Graphs, are graphical tools whose primary purpose is to enable investigators to detect confounding biases.

Their primary purpose is to equip investigators with strategies for addressing the demands of internal validity: the associations we obtain in our analysis consistently estimate causal associations for the population of interest.  We will assume that the population of interest -- the target population -- is the sample population at baseline.  We do this to better distinguish between the concepts of internal and external validity. Later, we will relax this assumption.  


We begin with by stating variable naming conventions that we will use throughout this course. 

::: {#fig-conventions}
![](terminologylocalconventions.pdf){fig-align="left" height=100% width=100%}

Variable naming conventions
:::

The symbol $X$ generically denotes a variable, without reference to its role.

$A$ denotes the "treatment" or "exposure" variable. This is the variable for which we seek to understand the effect of intervening on it. It is the "cause." 

$Y$ denotes the outcome or response of an intervention. It is the "effect" 

$Y(a)$ denotes the counterfactual or potential state of the outcome $Y$ in response to setting the level of the exposure to a specific level, $A=a$. As we will consider in the second half of the course, to consistently estimate causal effects we will need to evaluate counterfactual or potential states of the world. Don't worry about them for now -- all will become clear!

$L$ denotes a measured confounder or set of confounders is defined as a variable which, if conditioned upon, closes an open back-door path between the treatment $A$ and the outcome $Y$.


::: {#fig-general}
![](terminologygeneral.pdf){fig-align="left" height=100% width=100%}

Nodes, Edges, Conditioning Conventions
:::



::: {#fig-directedgraph}
![](terminologydirectedgraph.pdf){fig-align="left" height=100% width=100%}

Five elementary structures

:::






::: {#fig-terminologyconfounders}
![](terminologyelconfounders.pdf){fig-align="left" height=100% width=100%}

Four rules of confounding control

:::



## Lab -- Regression in R: Simulate The Five Fundamental Structures of Causality



## Simulating Data in R:  `Outcome ~ Treatment`


#### Step 1: Set Up Your R Environment

Ensure R or RStudio is installed and open. 


#### Step 2: Set a Seed for Reproducibility

To ensure that your simulated data can be reproduced exactly. Again, it is good practice to set a seed before generating random data. This makes your analyses and simulations replicable.

```{r}
set.seed(123) # use any number to set the seed
```

#### Step 3: Simulate Continuous Data: One Variable 

To simulate continuous data, you can use functions like `rnorm()` for normal distributions, `runif()` for uniform distributions, etc. Here we simulate 100 normally distributed data points with a mean of 50 and a standard deviation of 10:

```{r}
n <- 100 # number of observations
mean <- 50
sd <- 10
data_continuous <- rnorm(n, mean, sd)

# view
head(data_continuous)

# view
hist(data_continuous)
```


#### Step 4: Simulating Categorical Data

Categorical data can be simulated using the `sample()` function. Here, we simulate a binary variable (gender) with two levels for 100 observations. There is equal probability of assignment.

```{r}
levels <- c("Male", "Female")
data_categorical <- sample(levels, n, replace = TRUE)

# view
head(data_categorical)

```

To generate categories with unequal probabilities, you can use the `sample()` function by specifying the `prob` parameter, which defines the probability of selecting each level. This allows for simulating categorical data where the distribution between categories is not uniform. 

Below is an example that modifies your initial code to create a categorical variable with unequal probabilities for "Male" and "Female". Here is an example with unequal probabilities:

```{r}
#| echo: true
#| eval: false

# Define levels and number of observations
levels <- c("Male", "Female")
n <- 100 # total number of observations

# Generate categorical data with unequal probabilities
data_categorical_unequal <- sample(levels, n, replace = TRUE, prob = c(0.3, 0.7))

# View the first few elements
head(data_categorical_unequal)
```

In this example, the `prob` parameter is set to `c(0.3, 0.7)`, indicating a 30% probability for "Male" and a 70% probability for "Female". This results in a simulated dataset where approximately 30% of the observations are "Male" and 70% are "Female", reflecting the specified unequal probabilities. Adjust the probabilities as needed to fit the scenario you wish to simulate.


```{r simulate-data}
set.seed(123) #  reproducibility
groupA_scores <- rnorm(100, mean = 100, sd = 15) # simulate scores for group A
groupB_scores <- rnorm(100, mean = 105, sd = 15) # simulate scores for group B

# ombine into a data frame
scores_df <- data.frame(Group = rep(c("A", "B"), each = 100), Scores = c(groupA_scores, groupB_scores))

# commands to view data
str(scores_df)

# summary of columns
summary(scores_df)

# top rows
head(scores_df)

# bottom rows
tail(scores_df)
```


## Visualising simulated data

Understanding your data visually is as important as the statistical analysis itself. Let's create a simple plot to compare the score distributions between the two groups.

```{r visualize-data, fig.cap="Score Distribution by Group"}
if (!require(ggplot2)) {
  install.packages("ggplot2")
  library(ggplot2)
} else {
  library(ggplot2)
}

# plot your data
ggplot(scores_df, aes(x = Group, y = Scores, fill = Group)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Score Distribution by Group", x = "Group", y = "Scores")
```


## Histogram {#sec-histogram}

```{r}
library(ggplot2)

# H=histograms for both groups
ggplot(scores_df, aes(x = Scores, fill = Group)) +
  geom_histogram(binwidth = 5, color = "black") +
  labs(title = "Distribution of Scores",
       x = "Scores",
       y = "Frequency") +
  facet_wrap(~Group, ncol = 1)

```


## Excercise 1

1. Modify the simulation parameters to change each group's mean and standard deviation. Observe how these changes affect the distribution.

2. Go to the [histogram](#sec-histogram). Experiment with different bin widths. In your own words, how do large and small numbers speak differently to the data? When might you use one histogram and not another. 


## Simulating data for familiar statistical tests 


```{r}
# simulate some data
data <- rnorm(100, mean = 5, sd = 1) # 100 random normal values with mean = 5

# perform one-sample t-test
# testing if the mean of the data is reliably different from 4
t.test(data, mu = 4)

```

```{r}
# simulate data for two groups
group1 <- rnorm(50, mean = 5, sd = 1) # 50 random normal values, mean = 5
group2 <- rnorm(50, mean = 5.5, sd = 1) # 50 random normal values, mean = 5.5

# two-sample t-test
t.test(group1, group2)
```

```{r}
# simulate pre-test and post-test scores
pre_test <- rnorm(30, mean = 80, sd = 10)
post_test <- rnorm(30, mean =  pre_test + 5, sd = 5) # assume an increase

# perform paired t-test
t.test(pre_test, post_test, paired = TRUE)
```

## **Exercise 2: Linear Regression Analysis with Simulated Data**

#### **Task 1: Simulating Continuous Treatment Variable**

```{r}
#| echo: true
#| eval: false

# library for enhanced model reporting
library(parameters)

# set seed for reproducibility
set.seed(123) # choose a seed number for consistency

# define the number of observations
n <- 100 # total observations

# simulate continuous treatment variable A
a <- rnorm(n, mean = 50, sd = 10) # mean = 50, sd = 10 for A

# specify the effect size of A on Y
beta_a <- 2 # explicit effect size

# simulate outcome variable Y including an error term
y <- 5 + beta_a * a + rnorm(n, mean = 0, sd = 20) # Y = intercept + beta_a*A + error

# create a dataframe
df <- data.frame(a = a, y = y)

# view the structure and first few rows of the dataframe
str(df)
head(df)
```

#### **Task 2: Exploring the Simulated Data**

Before moving on to regression analysis, ensure students understand the structure and distribution of the simulated data. Encourage them to use `summary()`, `plot()`, and other exploratory data analysis functions.

#### **Task 3: Regression Analysis of Continuous Treatment Effect**

```{r}
#| echo: true
#| eval: false

# perform linear regression of Y on A
fit <- lm(y ~ a, data = df)

# display the regression model summary
summary(fit)

# report the model in a reader-friendly format
report_fit <- report::report(fit)
print(report_fit)

# optionally, visualize the relationship
plot(df$a, df$y, main = "Scatterplot of Y vs. A", xlab = "Treatment (A)", ylab = "Outcome (Y)")
abline(fit, col = "red")
```



## Equivalence of ANOVA and Regression


We will simulate data in R to show that a one-way ANOVA is a special case of linear regression with categorical predictors. We will give some reasons for preferring regression (in some settings).

## Method

First, we simulate a dataset with one categorical independent variable with three levels (groups) and a continuous outcome (also called a "dependant") variable. This setup allows us to apply both ANOVA and linear regression for comparison.

```{r}
# nice tables
if (!require(parameters)) {
  install.packages("parameters")
  library(parameters)
} else {
  library(parameters)
}


set.seed(321) # reproducibility
n <- 90 # total number of observations
k <- 3 # number of groups

# simulate independent variable (grouping factor)
group <- factor(rep(1:k, each = n/k))

# inspect
str(group)

# simulate outcome variable
means <- c(100, 100, 220) # Mean for each group
sd <- 15 # Standard deviation (same for all groups)

# generate random data
y <- rnorm(n, mean = rep(means, each = n/k), sd = sd)


# make data frame
df_1 <- cbind.data.frame(y, group)

anova_model <- aov(y ~ group, data = df_1)
# summary(anova_model)
table_anova <- model_parameters(anova_model)

# report the model
report::report(anova_model)
```


Next, we analyse the same data using linear regression. In R, regression models automatically convert categorical variables into dummy variables.

```{r}
# for tables (just installed)
library(parameters)

# regression model 
fit <- lm(y ~ group, data = df_1)

# uncomment if you want an ordinary summary
# summary(regression_model)

table_fit <- parameters::model_parameters(fit)

# print table
table_fit
```

```{r}
library(parameters)
library(report)

# report the model
report_fit <- report_parameters(fit)

#print
report_fit
```


## Upshot

ANOVA partitions variance into between-group and within-group components, while regression models the mean of the dependent variable as a linear function of the independent (including categorical) variables. For many questions, ANOVA is appropriate, however, when we are comparing groups, we often want a finer-grained interpretation. Regression is built for obtaining this finer grain understanding. We will return to regression over the next few weeks and use regression to hone your skills in R. Later, Along the way, you'll learn more about data visualisation, modelling, and reporting.  

```{r}
# graph the output of the parameters table
# visualisation
plot(table_fit)
```

### Exercise 2

Perform a linear regression analysis using R. Follow the detailed instructions below to simulate the necessary data, execute the regression, and report your findings:

1. **Simulate Data:**
   - Generate two continuous variables, `Y` and `A`, with `n = 100` observations each.
   - The variable `A` should have a mean of `50` and a standard deviation (`sd`) of `10`.

2. **Define the Relationship:**
   - Simulate the variable `Y` such that it is linearly related to `A` with a specified effect size. The effect size of `A` on `Y` must be explicitly defined as `2`.

3. **Incorporate an Error Term:**
   - When simulating `Y`, include an error term with a standard deviation (`sd`) of `20` to introduce variability.

4. **Regression Analysis:**
   - Use the `lm()` function in R to regress `Y` on `A`.
   - Ensure the regression model captures the specified effect of `A` on `Y`.

5. **Report the Results:**
   - Output the regression model summary to examine the coefficients, including the effect of `A` on `Y`, and assess the model's overall fit and significance.


Here is a template to get you started. Copy the code and paste it into your R script. 



```{r}
#| echo: true
#| eval: false


library(parameters)
#  seed for reproducibility
set.seed( ) # numbers go in brackets

# number of observations
n <-   # number goes here

# simulate data for variable A with specified mean and sd
A <- rnorm(n, 
           mean = , # set your number here 
           sd = )# set your number here 

# define the specified effect size of A on Y
beta_A <-   # define your effect with a number here 


# simulate data and make data frame in one step

df_3 <- data.frame(
  # simulate data for variable A with specified mean and sd
  A = A, # from above
  Y = 5 + beta_A * A + rnorm(n, mean = 0, sd = 20) #  effect is intercept + ...
)

# view
head(df_3)
str(df_3)

#  linear regression of Y on A
fit_3 <- lm(Y ~ A, data = df_3)

#  results (standard code)
# summary(model)

# time saving reports
parameters::model_parameters(fit_3)
report(fit_3)

```



#### Step 5: Simulating Data Frames

Data frames are used in R to store data tables. To simulate a dataset with both continuous and categorical data, you can combine the above steps:

```{r}
# create a data frame with simulated data for ID, Gender, Age, and Income
data_frame <- data.frame(
  # generate a sequence of IDs from 1 to n
  ID = 1:n,
  
  # randomly assign 'Male' or 'Female' to each observation
  Gender = sample(c("Male", "Female"), n, replace = TRUE),
  
  # simulate 'Age' data: normally distributed with mean 30 and sd 5
  Age = rnorm(n, mean = 30, sd = 5),
  
  # simulate 'Income' data: normally distributed with mean 50000 and sd 10000
  Income = rnorm(n, mean = 50000, sd = 10000)
)
```


Note that you can sample probabilistically for your groups

```{r}
n <- 100 # total number of observations

# sample 'Gender' with a 40/60 proportion for Male/Female
Gender = sample(c("Male", "Female"), n, replace = TRUE, prob = c(0.4, 0.6))
```

## More complexity 

```{r}
# set the number of observations
n <- 100

# simulate the 'Age' variable
mean_age <- 30
sd_age <- 5
Age <- rnorm(n, mean = mean_age, sd = sd_age)

# define coefficients explicitly
intercept <- 20000   # Intercept for the income equation
beta_age <- 1500     # Coefficient for the effect of age on income
error_sd <- 10000    # Standard deviation of the error term

# simulate 'Income' based on 'Age' and defined coefficients
Income <- intercept + beta_age * Age + rnorm(n, mean = 0, sd = error_sd)

# create a data frame to hold the simulated data
data_complex <- data.frame(Age, Income)
```

#### Step 7: Visualising Simulated Data

Visualising your simulated data can help understand its distribution and relationships. Use the `ggplot2` package for this:

```{r}
library(ggplot2)
ggplot(data_complex, aes(x = Age, y = Income)) +
  geom_point() +
  theme_minimal() +
  labs(title = "Simulated Age vs. Income", x = "Age", y = "Income")
```


## Practice
Simulating data is a powerful method to understand statistical concepts and data manipulation. Let's simulate a simple dataset representing scores from two cultural groups.


- **Data simulation:** 

You've learned to simulate datasets in R. This is a foundational skill for exploring statistical concepts and data manipulation techniques. Congratulations! 


## Appendix A: Solutions {#appendix-a}


### Solution Excercise 2: simulate data and regression reporting 


```{r}
library(parameters)
#  seed for reproducibility
set.seed(12345)

# number of observations
n <- 100

# simulate data for variable A with specified mean and sd
A <- rnorm(n, mean = 50, sd = 10)

# define the specified effect size of A on Y
beta_A <- 2


# simulate data and make data frame in one step

df_3 <- data.frame(
  # simulate data for variable A with specified mean and sd
  A =  rnorm(n, mean = 50, sd = 10),
  Y = 5 + beta_A * A + rnorm(n, mean = 0, sd = 20)
)

# view
head(df_3)
str(df_3)
# Perform linear regression of Y on A

fit_3 <- lm(Y ~ A, data = df_3)

# Report the results of the regression
# summary(model)

# report
parameters::model_parameters(fit_3)
report(fit_3)


```



## What You Have Learned

- **Data simulation:** 

You've learned to simulate datasets in R. This is a foundational skill for exploring statistical concepts and data manipulation techniques. Congratulations! 
  
- **Data visualisation:** 

You've begun data visualising data through boxplots and histograms and coefficient plots, which is crucial for analysing and communicating statistical findings.
  
- **Statistical tests:** You've conducted basic statistical tests, including t-tests and ANOVA, gaining insights into comparing means across groups.
  
- **Understanding ANOVA and regression:** 

You've explored the equivalence of ANOVA and regression analysis, learning how these methods can be applied to analyse and interpret data effectively.


## For more information about the packages used here:

  - [ggplot2](https://ggplot2.tidyverse.org/): A system for declaratively creating graphics, based on The Grammar of Graphics.

  - [Parameters package](https://easystats.github.io/parameters/): Provides utilities for processing model parameters and their metrics.

  - [Report package](https://easystats.github.io/report/index.html): Facilitates the automated generation of reports from statistical models.

## Appendix B: How ANOVA can deliever the functionality of Linear Regressions

We can get group comparisons with ANOVA, for example:

```{r}
# Conduct Tukey's HSD test for post-hoc comparisons
tukey_post_hoc <- TukeyHSD(anova_model)

# Display the results
print(tukey_post_hoc)
plot(tukey_post_hoc)
```

Regression and ANOVA are equivalent



## Appendix C: Glossary:

Creating a table format for your comprehensive glossary in a markdown document, given the extensive list, it's practical to focus on key terms for brevity and clarity. Here's a condensed table representation:



| Term                                   | Definition                                                                                                                                                   |
|----------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Acyclic**                            | In causal diagrams, no variable can be an ancestor or descendant of itself; no feedback loops allowed.                                                       |
| **Adjustment Set**                     | Variables conditioned to block all backdoor paths between treatment ($A$) and outcome ($Y$), ensuring unbiased causal estimates.                             |
| **Ancestor (Parent)**                  | A node affecting others downstream in the causal chain, preceding its descendants in time.                                                                   |
| **Arrow**                              | Represents direct causation in causal DAGs, pointing from cause to effect.                                                                                   |
| **Average Treatment Effect (ATE)**     | The difference in expected outcomes between treated and untreated units across a population.                                                                 |
| **Backdoor Path**                      | Paths introducing potential confounding bias between treatment and outcome, requiring blocking for unbiased estimation.                                      |
| **Causal Contrast**                    | The difference in expected outcomes under different treatment levels across a population.                                                                    |
| **Causal Contrast Scale**              | The metric for quantifying causal contrasts, chosen based on outcome type and research question.                                                             |
| **Causal Diagram (Causal DAG)**        | Graphs representing causal relationships; must be acyclic and capture all confounding sources.                                                               |
| **Causal Estimand**                    | The causal contrast of interest specifying intervention, outcome, contrast scale, and target population; given before analysis.                             |
| **Causal Path**                        | Asserts a change in the parent node will induce a change in its child.                                                                                       |
| **Censoring**                          | Incomplete data in longitudinal studies due to unobserved relevant events, sample attrition, including right, left, and interval censoring.                  |
| **Collider**                           | A variable where two causal paths meet head-to-head, leading to non-causal associations between any unassociated parents.                                    |
| **Conditional Average Treatment Effect (CATE)** | The treatment effect for specific subgroups, defined by explicit characteristics.                                                                          |
| **Conditioning**                       | Adjusting for variables in analysis to distinguish causal effects from associations.                                                                         |
| **Confounding**                        | Treatment and outcome are associated independently of causality or disassociated in the presence of causality.                                               |
| **Confounder**                         | A variable that, when conditioned upon, reduces or eliminates confounding; its role is relative to the causal question and conditioning strategy.             |
| **Counterfactual or Potential outcomes** | Hypothetical outcomes under different treatment conditions to be contrasted, only one may be realised for each observed unit.                              |
| **d-separation**                       | Backdoor paths are blocked, indicating conditional independence.                                                                                             |
| **Descendant (Child)**                 | A node causally influenced by a prior node (Parent). A child is a direct descendant.                                                                         |
| **Effect-Measure Modifier/Effect-Modifier** | A variable that affects the magnitude or direction of a causal effect.                                                                                    |
| **Estimator**                          | Algorithm to compute a statistical estimand from data.                                                                                                       |
| **External Validity/Target Validity**  | The generalisability of study findings to the prespecified target population; assumes internal validity.                                                     |
| **Heterogeneous Treatment Effects**    | Variation in treatment effects across subgroups or contexts.                                                                                                 |
| **Identification Problem**             | Estimating causal effects accurately by adjusting for confounding.                                                                                           |
| **Incident Exposure Effect**           | Describes the effect of initiating a new treatment.                                                                                                          |
| **Indirect Effect (Mediated Effect)**  | The effect portion transmitted through a mediator in the causal pathway.                                                                                     |
| **Instrumental Variable**              | Associated with treatment but affecting the outcome only through the treatment, used for estimating causal effects amidst confounding.                        |
| **Intention-to-Treat Effect**          | The effect of treatment assignment, analysed based on initial treatment assignment, reflecting real-world effectiveness but possibly obscuring mechanisms.    |
| **Internal Validity**                  | The extent to which causal associations in the study population are accurately identified.                                                                    |
| **Inverse Probability of Censoring Weights (IPCW)** | Adjust for bias from attrition in longitudinal studies.                                                                       |
| **Inverse Probability of Treatment Weights (IPTW)** | Creates a pseudo-population to obtain treatment balance across conditions.                                                                              |
| **Loss-to-follow-up**                  | Participant attrition.                                                                                                                                       |
| **Marginal effect**                    | Synonymous with Average Treatment Effect.                                                                                                                    |
| **Mediator**                           | A variable through which a treatment affects an outcome.                                                                                                     |
| **Node**                               | Represents a variable in a causal diagram.                                                                                                                   |
| **Observational Study**                | Research in which treatment assignment is not controlled by the investigator.                                                                                |
| **Path**                               | Association between variables in a causal diagram.                                                                                                           |
| **Per-Protocol Effect**                | The causal effect under full-treatment adherence.                                                                                                            |
| **Prevalent Exposure Effect**          | Describes the effect of current or ongoing exposures.                                                                                                        |
| **Propensity Score**                   | The probability of receiving treatment based on observed characteristics, used for confounding adjustment in observational studies.                          |
| **Randomisation**                      | Assigning treatments randomly to balance confounders across treatment conditions.                                                                            |
| **Randomised Controlled Trial (RCT)**  | The "gold standard" uses random treatment assignment to ensure unbiased causal inference.                                                                    |
| **Reverse Causation**                  | Cause and effect are mistakenly conflated in analysis.                                                                                                       |
| **Sample Weights**                     | Adjusts sample data to better represent the target population in analysis.                                                                                   |
| **Selection Bias**                     | Systematic errors from non-representative study participation or attrition, affecting generalisability.                                                      |
| **Sequentially ordered causal diagram**| Diagrams where nodes and arrows align with temporal sequence.                                                                                                |
| **Statistical Estimand**               | The parameter of interest in a statistical model, not necessarily causal.                                                                                    |
| **Statistical Estimate**               | The value obtained for a statistical estimand from data analysis.                                                                                            |
| **Statistical Model**                  | Mathematical relationships between dataset variables; does not inherently identify causation without structural assumptions.                                  |
| **Structural Model**                   | Assumptions about causal relationships encoded in diagrams, essential for causal interpretation beyond mere statistical association.                         |
| **Study Population**                   | The actual population from which data are collected, also termed "sample population."                                                                       |
| **Target Population**                  | The broader population to which study results are intended to apply.                                                                                         |
| **Target Trial**                       | An observational study that attempts to emulate an idealised experiment by pre-specifying a causal estimand, eligibility criteria, and appropriate data ordering.|
| **Time-Varying Confounding**           | Confounding that changes over time, complicating causal effect estimation with standard methods.                                                             |
